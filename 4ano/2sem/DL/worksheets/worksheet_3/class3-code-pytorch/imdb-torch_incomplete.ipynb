{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cced0a59-5ad2-4e05-afad-7b46b7c7f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb4545a-6e27-4e9d-8d8b-541842981bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB text files manually\n",
    "\n",
    "def load_imdb_split(folder):\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    for label_type in [\"pos\", \"neg\"]:\n",
    "        path = os.path.join(folder, label_type)\n",
    "\n",
    "        for fname in os.listdir(path):\n",
    "            if fname.endswith(\".txt\"):\n",
    "                with open(os.path.join(path, fname), encoding=\"utf-8\") as f:\n",
    "                    texts.append(f.read())\n",
    "                labels.append(1 if label_type == \"pos\" else 0)\n",
    "\n",
    "    return texts, np.array(labels, dtype=np.float32)\n",
    "\n",
    "\n",
    "base_dir = \"./aclImdb\"  # <-- change if needed\n",
    "\n",
    "train_texts, train_labels = load_imdb_split(os.path.join(base_dir, \"train\"))\n",
    "test_texts, test_labels = load_imdb_split(os.path.join(base_dir, \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d2a1620-8d0d-471b-bca1-34e58e2f047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words vectorization (10k words)\n",
    "\n",
    "max_words = 10000\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=max_words,\n",
    "    binary=True,\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "x_train = vectorizer.fit_transform(train_texts).toarray().astype(np.float32)\n",
    "x_test = vectorizer.transform(test_texts).toarray().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10efaef7-02a3-4b45-a65c-9c6399c3ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, train_labels, test_size=10000, random_state=42, stratify=train_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3796a5a9-8d06-45e1-b789-d397b75c7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x_train = torch.tensor(x_train).to(device)\n",
    "y_train = torch.tensor(y_train).unsqueeze(1).to(device)\n",
    "\n",
    "x_val = torch.tensor(x_val).to(device)\n",
    "y_val = torch.tensor(y_val).unsqueeze(1).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
