{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fac377d",
   "metadata": {},
   "source": [
    "## Introduction to deep learning - exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15746453",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "*Human Activity Recognition using Smartphones* dataset\n",
    "\n",
    "Dataset description:\n",
    "\n",
    "*The experiments have been carried out with a group of 30 volunteers. Each person performed six activities\n",
    "(WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone.\n",
    "Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity.\n",
    "The experiments have been video-recorded to label the data manually.*\n",
    "\n",
    "**Variables:**\n",
    "For each record in the dataset it is provided:\n",
    "* A 561-feature vector with time and frequency domain variables.\n",
    "* Its activity label.\n",
    "* An identifier of the subject who carried out the experiment.\n",
    "\n",
    "More details at: https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32b7a9",
   "metadata": {},
   "source": [
    "### Loading and preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c5743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e5e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = ''  ## put here folder where the file HAR_clean.csv is located"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79540a9d",
   "metadata": {},
   "source": [
    "Load the dataset: \"HAR_clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b430687",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(os.path.join(folder, 'HAR_clean.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f435d7",
   "metadata": {},
   "source": [
    "Divide into input and output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a9c1de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299, 561)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = all_data.iloc[:,:-2].values.astype(np.float32)\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b42b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10299,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = all_data.iloc[:,-1].values\n",
    "output_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477cce00",
   "metadata": {},
   "source": [
    "Divide the data into train and test, keeping 30% for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be1cf55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7209, 561) (7209,)\n",
      "(3090, 561) (3090,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, output_data, test_size=0.3)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa30e7f",
   "metadata": {},
   "source": [
    "### Best shallow ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7beffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1000, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':['linear', 'rbf'], 'C':[1, 10, 100,1000], 'gamma':[0.01, 0.001]}\n",
    "\n",
    "svm_model_d = svm.SVC()\n",
    "opt_model_d = GridSearchCV(svm_model_d, parameters)\n",
    "\n",
    "opt_model_d.fit(X_train, y_train)\n",
    "print (opt_model_d.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf6296f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.983495145631068"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_model_d.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce6f06",
   "metadata": {},
   "source": [
    "### Training a DL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f9ce563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(y_train)\n",
    "\n",
    "y_train_encoded = le.transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab93bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train)\n",
    "y_train = torch.tensor(y_train_encoded)\n",
    "\n",
    "X_test = torch.tensor(X_test)\n",
    "y_test = torch.tensor(y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884dd19-68f1-4348-9e66-8489233b67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN model - define here the model - complete\n",
    "\n",
    "class HARNet(nn.Module):\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = None ## complete here\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "model = HARNet(n_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7879404-b517-4e40-9002-5595cf93b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss & optimizer - complete !\n",
    "criterion = None # complete here\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d31491-4422-4ba8-a1b3-80d80b52e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Training loop\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # ---- mini-batch training ----\n",
    "    perm = torch.randperm(X_train.size(0))\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        idx = perm[i:i + batch_size]\n",
    "        xb, yb = X_train[idx], y_train[idx]\n",
    "\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    # ---- evaluation ----\n",
    "    with torch.no_grad():\n",
    "        logits = model(X_test)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy_score(y_test.numpy(), preds.numpy())\n",
    "        test_accuracies.append(acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | Loss: {epoch_loss:.3f} | Test Acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0fae87-9cad-46a0-8fff-187ac4b015fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set evaluation\n",
    "print(\"\\nFinal test accuracy:\", test_accuracies[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e5259-2749-4c9d-83eb-f6772b5ded37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
