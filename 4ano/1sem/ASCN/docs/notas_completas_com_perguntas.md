# AplicaÃ§Ãµes e ServiÃ§os de ComputaÃ§Ã£o em Nuvem
## Notas de Aula + Perguntas Integradas

_Notas de aula â€” ASCN Â· 4.Âº ano, 1.Âº semestre_
_Com 25 Perguntas distribuÃ­das por capÃ­tulo/secÃ§Ã£o correspondente_

---

## Ãndice

1. [MotivaÃ§Ã£o e objetivos](#1-motivaÃ§Ã£o-e-objetivos)
2. [Modelos de AplicaÃ§Ã£o](#2-modelos-de-aplicaÃ§Ã£o)
3. [Desafios comuns](#3-desafios-comuns)
4. [Netflix](#4-netflix)
5. [O Motor de Consultas do Facebook: Presto](#5-o-motor-de-consultas-do-facebook-presto)
6. [HBase no Facebook](#6-hbase-no-facebook)
7. [Agile, ciclo de entrega e operaÃ§Ãµes](#7-agile-ciclo-de-entrega-e-operaÃ§Ãµes)
8. [Infrastructure as Code (IaC)](#8-infrastructure-as-code-iac)
9. [DevOps](#9-devops)
10. [Arquitetura MonolÃ­tica](#10-arquitetura-monolÃ­tica)
11. [Arquitetura de MicroserviÃ§os](#11-arquitetura-de-microserviÃ§os)
12. [Arquiteturas distribuÃ­das (padrÃµes)](#12-arquiteturas-distribuÃ­das-padrÃµes)
13. [PadrÃµes de sistemas distribuÃ­dos](#13-padrÃµes-de-sistemas-distribuÃ­dos)
14. [Provisioning & Deployment](#14-provisioning--deployment)
15. [AutomatizaÃ§Ã£o de tarefas](#15-automatizaÃ§Ã£o-de-tarefas)
16. [ConfiguraÃ§Ã£o e ManutenÃ§Ã£o - SoluÃ§Ãµes Modernas](#16-configuraÃ§Ã£o-e-manutenÃ§Ã£o---soluÃ§Ãµes-modernas)
17. [Ansible (resumo)](#17-ansible-resumo)
18. [Cloud Services (IaaS / PaaS / SaaS)](#18-cloud-services-iaas--paas--saas)
19. [OpenStack - construÃ§Ã£o de uma nuvem IaaS](#19-openstack---construÃ§Ã£o-de-uma-nuvem-iaas)
20. [Elasticidade, automaÃ§Ã£o e conveniÃªncia](#20-elasticidade-automaÃ§Ã£o-e-conveniÃªncia)
21. [VirtualizaÃ§Ã£o](#21-virtualizaÃ§Ã£o)
22. [Containers](#22-containers)
23. [DOCKER](#23-docker)
24. [KUBERNETES](#24-kubernetes)
25. [Storage](#25-storage)
26. [MonitorizaÃ§Ã£o](#26-monitorizaÃ§Ã£o)
27. [Benchmarking](#27-benchmarking)
28. [ApÃªndice â€” termos e definiÃ§Ãµes](#28-apÃªndice--termos-e-definiÃ§Ãµes)

---

## 21. VirtualizaÃ§Ã£o

### FundamentaÃ§Ã£o

A virtualizaÃ§Ã£o Ã© uma abstraÃ§Ã£o fundamental que permite criar mÃºltiplas representaÃ§Ãµes lÃ³gicas (mÃ¡quinas virtuais) a partir de um Ãºnico recurso fÃ­sico (servidor). Esta abstraÃ§Ã£o resolve problemas crÃ­ticos de infraestrutura.

**Problema Original (PrÃ©-2000):**
- Cada aplicaÃ§Ã£o necessitava de servidor dedicado
- SubutilizaÃ§Ã£o significativa de recursos (tipicamente 15-30% de CPU)
- Custos elevados de infraestrutura e espaÃ§o em data center
- GestÃ£o heterogÃ©nea

**SoluÃ§Ã£o: Os TrÃªs Pilares da VirtualizaÃ§Ã£o**

1. **ConsolidaÃ§Ã£o e EficiÃªncia**: MÃºltiplos SOs no mesmo hardware
2. **Isolamento e SeguranÃ§a**: Cada VM isolada atravÃ©s do hypervisor
3. **AbstraÃ§Ã£o e TransparÃªncia**: Portabilidade total de aplicaÃ§Ãµes

### 21.1 Hypervisor

Um hypervisor Ã© o software fundamental que intermedia acesso de VMs ao hardware fÃ­sico.

**Responsabilidades:**
- GestÃ£o de CPU: Interceta e traduz instruÃ§Ãµes privilegiadas
- GestÃ£o de MemÃ³ria: Virtualiza espaÃ§o de endereÃ§os
- GestÃ£o de I/O: Cria abstraÃ§Ãµes de dispositivos virtuais
- GestÃ£o de Rede: Implementa bridges virtuais ou NAT

### 21.2 Partilha de CPU, MemÃ³ria e Armazenamento

**Partilha de CPU (Time-slicing)**: MÃºltiplas VMs partilham cores atravÃ©s de escalonamento

**Partilha de MemÃ³ria**: Cada VM tem espaÃ§o de endereÃ§os virtual. Shadow page tables criam mapeamento host-guest

**Partilha de Armazenamento**: VMs veem discos virtuais que mapeiam ficheiros ou discos fÃ­sicos

### 21.3 GestÃ£o de Rede

**Bridge Virtual**: Liga mÃºltiplas VMs e anfitriÃ£o numa rede virtual

**NAT Virtual**: VMs acesso a rede externa atravÃ©s de traduÃ§Ã£o de endereÃ§os

**VLAN (Virtual LAN)**: Isola trÃ¡fego entre VMs

### 21.4 VirtualizaÃ§Ã£o Completa vs ParavirtualizaÃ§Ã£o

| Aspeto | VirtualizaÃ§Ã£o Completa | ParavirtualizaÃ§Ã£o |
|--------|----------------------|------------------|
| **ModificaÃ§Ã£o SO Convidado** | Nenhuma | NecessÃ¡ria (hooks) |
| **TraduÃ§Ã£o InstruÃ§Ãµes** | Completa (Intel VT-x/AMD-V) | Parcial |
| **Desempenho** | Bom (com hardware support) | Excelente |
| **Portabilidade** | MÃ¡xima | Limitada |
| **Exemplos** | VirtualBox, VMware | Xen |

#### Tipos de Hypervisor

**Tipo 1 (Bare Metal):**
- Instalado diretamente no hardware
- Funciona como "micro kernel" otimizado
- Desempenho mÃ¡ximo
- Exemplos: VMware ESX, KVM
- Caso de uso: Data centers de produÃ§Ã£o

**Tipo 2 (Hosted):**
- Instalado como aplicaÃ§Ã£o sobre SO de propÃ³sito geral
- Overhead do SO anfitriÃ£o reduz desempenho
- Flexibilidade mÃ¡xima
- Exemplos: VirtualBox, Parallels
- Caso de uso: Desenvolvimento local

---

### ğŸ¯ PERGUNTAS SOBRE VIRTUALIZAÃ‡ÃƒO

**Pergunta 1: ComparaÃ§Ã£o de Abordagens de VirtualizaÃ§Ã£o**

Concorda com a afirmaÃ§Ã£o de que "a virtualizaÃ§Ã£o completa (full virtualization) Ã© sempre preferÃ­vel Ã  paravirtualizaÃ§Ã£o em termos de desempenho global"? Justifique a sua resposta com exemplos concretos.

**Resposta:**
Discordo parcialmente. Embora ambas as abordagens tenham vantagens e desvantagens distintas:

**VirtualizaÃ§Ã£o Completa (ex: VirtualBox):**
- **Vantagem**: Maior portabilidade â€“ o SO convidado nÃ£o requer modificaÃ§Ãµes
- **Desvantagem**: Menor desempenho, pois todas as instruÃ§Ãµes do SO convidado devem ser traduzidas para o hardware fÃ­sico

**ParavirtualizaÃ§Ã£o (ex: Xen):**
- **Vantagem**: Melhor desempenho de CPU e I/O, pois o SO convidado contÃ©m "hooks" (modificaÃ§Ãµes) que evitam a traduÃ§Ã£o completa
- **Desvantagem**: Requer modificaÃ§Ãµes no SO convidado, prejudicando a portabilidade

**ConclusÃ£o**: A escolha depende do contexto. Para ambientes onde o desempenho Ã© crÃ­tico e as modificaÃ§Ãµes de SO sÃ£o aceitÃ¡veis, paravirtualizaÃ§Ã£o Ã© preferÃ­vel. Para mÃ¡xima compatibilidade e portabilidade, virtualizaÃ§Ã£o completa Ã© melhor.

---

**Pergunta 2: Hypervisors Tipo 1 vs Tipo 2**

Compare os hypervisors tipo 1 (bare metal) e tipo 2 (hosted), indicando um cenÃ¡rio onde cada um Ã© mais apropriado. Justifique.

**Resposta:**

| Aspeto | Tipo 1 (Bare Metal) | Tipo 2 (Hosted) |
|--------|-------------------|-----------------|
| **InstalaÃ§Ã£o** | Diretamente no hardware | Como aplicaÃ§Ã£o sobre SO |
| **Desempenho** | MÃ¡ximo (sem overhead de SO) | Reduzido (SO anfitriÃ£o consome recursos) |
| **Requisitos Hardware** | Suporte especÃ­fico de virtualizaÃ§Ã£o | Menos exigente |
| **Exemplo** | VMware ESX | VirtualBox, KVM |

**CenÃ¡rios apropriados:**
- **Tipo 1**: Centros de dados e ambientes de produÃ§Ã£o onde o desempenho mÃ¡ximo Ã© crÃ­tico (ex: hospedagem de mÃºltiplas VMs em escala)
- **Tipo 2**: Desenvolvimento local, testes e mÃ¡quinas pessoais onde a flexibilidade e facilidade de instalaÃ§Ã£o sÃ£o prioritÃ¡rias

---

**Pergunta 3: Os TrÃªs Pilares da VirtualizaÃ§Ã£o**

Indique e explique os trÃªs pilares fundamentais que justificam o uso da virtualizaÃ§Ã£o na cloud. DÃª exemplos prÃ¡ticos.

**Resposta:**

1. **ConsolidaÃ§Ã£o e EficiÃªncia**
   - MÃºltiplos SOs e aplicaÃ§Ãµes correm no mesmo hardware fÃ­sico
   - Exemplo: Um servidor fÃ­sico com 4 cores pode alocar 2 cores a uma VM Linux e 2 a uma VM Windows
   - BenefÃ­cio: ReduÃ§Ã£o de custos de infraestrutura e melhor utilizaÃ§Ã£o de recursos

2. **Isolamento e SeguranÃ§a**
   - Cada VM Ã© isolada; uma VM comprometida nÃ£o afeta outras
   - Exemplo: Se uma VM for atacada, as restantes continuam funcionais
   - BenefÃ­cio: SeguranÃ§a, desempenho dedicado e fiabilidade

3. **AbstraÃ§Ã£o e TransparÃªncia**
   - A heterogeneidade do hardware Ã© abstraÃ­da
   - Exemplo: Uma aplicaÃ§Ã£o desenvolvida para x86 pode correr em qualquer mÃ¡quina fÃ­sica x86 sem modificaÃ§Ãµes
   - BenefÃ­cio: Portabilidade e simplicidade para o utilizador final

---

## 22. Containers

**MotivaÃ§Ã£o: O Problema da Portabilidade**

Antes dos contentores, o ciclo de vida do desenvolvimento enfrentava desafios crÃ³nicos:

1. **Dependency Hell**: Conflitos entre versÃµes de bibliotecas
2. **InconsistÃªncia de Ambientes**: Dev, Teste, ProduÃ§Ã£o eram diferentes
3. **Peso das VMs**: Cada VM ocupa 50GB+, arranca em segundos/minutos

**Um contentor Ã© um ambiente virtual leve que:**
- Agrupa processos e recursos (CPU, memÃ³ria, disco)
- Isola aplicaÃ§Ã£o do sistema anfitriÃ£o
- Partilha o kernel do SO anfitriÃ£o (diferenÃ§a crÃ­tica com VMs)
- Empacota cÃ³digo + dependÃªncias + configuraÃ§Ã£o

### Tecnologia Subjacente (Linux Kernel)

Os contentores utilizam trÃªs mecanismos do kernel Linux:

#### 1. Namespaces (Isolamento)
Particionam recursos globais do kernel para cada contentor:
- **PID Namespace**: Contentor vÃª prÃ³prios PIDs
- **Network Namespace**: Interface de rede virtual prÃ³pria
- **Mount Namespace**: Sistema de ficheiros prÃ³prio

#### 2. Control Groups (cgroups) - GestÃ£o de Recursos
Limitam quantidade de recursos que cada contentor pode utilizar:
- **CPU**: Limitar a 1 core, mesmo se servidor tem 8
- **MemÃ³ria**: Limite mÃ¡ximo de 512MB
- **I/O**: LimitaÃ§Ãµes de banda de disco

#### 3. SELinux (SeguranÃ§a)
Adiciona controlo de acesso obrigatÃ³rio (MAC) para garantir isolamento.

---

### ğŸ¯ PERGUNTAS SOBRE CONTENTORES

**Pergunta 4: DiferenÃ§a Fundamental entre Imagens e Contentores Docker**

Qual Ã© a diferenÃ§a entre uma imagem Docker e um contentor Docker? Explique a relaÃ§Ã£o entre ambos.

**Resposta:**
- **Imagem Docker**: Um ficheiro imutÃ¡vel (read-only) que funciona como um "molde" ou "planta". ContÃ©m tudo o que Ã© necessÃ¡rio para executar uma aplicaÃ§Ã£o: cÃ³digo, dependÃªncias, bibliotecas, variÃ¡veis de ambiente, etc.
  
- **Contentor Docker**: Uma instÃ¢ncia em execuÃ§Ã£o de uma Imagem. Ã‰ o resultado de "executar" uma imagem. Um contentor tem estado mutÃ¡vel (pode ser modificado durante a execuÃ§Ã£o) e pode ser criado, reiniciado ou removido.

**Analogia**: Se uma Imagem Ã© um ficheiro executÃ¡vel (como um programa .exe), um Contentor Ã© o programa em execuÃ§Ã£o.

---

**Pergunta 5: Vantagens dos Contentores sobre MÃ¡quinas Virtuais**

Indique duas vantagens principais dos contentores relativamente Ã s mÃ¡quinas virtuais e explique o impacto na eficiÃªncia de infraestruturas de computaÃ§Ã£o em nuvem.

**Resposta:**

1. **Leveza e Velocidade de Arranque**
   - Contentores partilham o kernel do SO anfitriÃ£o, eliminando a necessidade de um SO completo por aplicaÃ§Ã£o
   - Uma VM necessita de 50GB+ de espaÃ§o, um contentor ocupa apenas alguns MB
   - Tempo de arranque: VM (~segundos a minutos), Contentor (<1 segundo)
   - **Impacto**: Escalabilidade horizontal mais rÃ¡pida em ambientes cloud. Com Kubernetes, podemos escalar aplicaÃ§Ãµes automaticamente em milissegundos

2. **Isolamento com EficiÃªncia**
   - Contentores utilizam namespaces e cgroups do Linux para isolar processos sem overhead completo de virtualizaÃ§Ã£o
   - MÃºltiplos contentores podem correr num Ãºnico servidor fÃ­sico
   - **Impacto**: Densidade de carga muito maior. Um servidor que suportaria 5-10 VMs pode suportar 100+ contentores, reduzindo custos de infraestrutura significativamente

---

**Pergunta 6: Docker vs MÃ¡quinas Virtuais em CenÃ¡rios EspecÃ­ficos**

Para replicar o servidor aplicacional da aplicaÃ§Ã£o Laravel.io, nÃ£o basta apenas criar vÃ¡rios pods Kubernetes deste servidor. Concorda com esta afirmaÃ§Ã£o? Justifique.

**Resposta:**
Concordo plenamente. Embora o Kubernetes facilite a replicaÃ§Ã£o de pods (contentores), isso Ã© apenas parte da soluÃ§Ã£o. Existem componentes que nÃ£o podem ser simplesmente replicados:

**Problemas que surgem:**
1. **Base de Dados**: NÃ£o se pode ter mÃºltiplas instÃ¢ncias de uma base de dados escrevendo nas mesmas tabelas sem mecanismos de sincronizaÃ§Ã£o (replicaÃ§Ã£o, clustering)
2. **SessÃµes de Utilizador**: Se um cliente Ã© atendido por um pod num pedido e por outro noutro pedido, Ã© necessÃ¡rio armazenamento de sessÃµes distribuÃ­do (Redis, Memcached)
3. **Sistema de Ficheiros Compartilhado**: Uploads de ficheiros necessitam de armazenamento persistente acessÃ­vel por todos os pods
4. **Estado Partilhado**: Caches, filas de mensagens, etc.

**SoluÃ§Ã£o completa necessÃ¡ria:**
- Replicar o servidor aplicacional (sim, com Kubernetes)
- Replicar/shardear a base de dados
- Implementar armazenamento distribuÃ­do (Volumes Kubernetes)
- Usar serviÃ§os de armazenamento temporÃ¡rio (Redis para sessÃµes)

---

## 23. DOCKER

Docker Ã© a implementaÃ§Ã£o mais popular de contentores. Oferece ferramentas para:
- **Build**: Criar imagens Docker
- **Ship**: Distribuir imagens via registry
- **Run**: Executar contentores

**Componentes Principais:**
1. **Docker Engine**: Runtime que executa contentores
2. **Docker Image**: Ficheiro binÃ¡rio com aplicaÃ§Ã£o empacotada
3. **Docker Container**: InstÃ¢ncia em execuÃ§Ã£o de uma imagem
4. **Docker Registry**: RepositÃ³rio centralizado de imagens (Docker Hub, Private Registry)

---

## 24. KUBERNETES

### MotivaÃ§Ã£o: Do Contentor Ã  Frota

Executar 1 contentor Ã© trivial. AplicaÃ§Ãµes modernas requerem dezenas ou centenas de contentores que precisam:
- DistribuiÃ§Ã£o automÃ¡tica por mÃºltiplos servidores
- ReplicaÃ§Ã£o para alta disponibilidade
- Auto-reparaÃ§Ã£o (reiniciar contentores que caem)
- Descoberta de serviÃ§os
- Balanceamento de carga
- Escalabilidade horizontal automÃ¡tica

### Arquitetura Kubernetes

Kubernetes Ã© um sistema operativo distribuÃ­do para contentores. Arquitetura mestre-escravo.

#### Control Plane (CÃ©rebro)
1. **API Server**: Ponto de entrada, fonte da verdade do cluster
2. **etcd**: Base de dados distribuÃ­da, armazena todo estado
3. **Scheduler**: Coloca pods nos nÃ³s considerando requisitos
4. **Controller Manager**: Garante estado desejado (ReplicaSet, Deployment, etc.)

#### Nodes (MÃºsculos)
Em cada nÃ³ corre:
1. **Kubelet**: Agente que assegura contentores estÃ£o a executar
2. **Container Runtime**: Executa contentores (Docker, containerd, rkt)
3. **Kube-proxy**: Gerencia rede, implementa serviÃ§os

### 24.1 Componentes principais

**Pod**: Unidade mais pequena no Kubernetes. Pode ter mÃºltiplos contentores que partilham rede.

**Deployment**: Objeto de alto nÃ­vel que define nÃºmero de rÃ©plicas desejadas. Kubernetes assegura que sempre corre o nÃºmero correto.

**Service**: AbstraÃ§Ã£o para descoberta de serviÃ§os. Fornece IP estÃ¡vel e DNS, balanceia trÃ¡fego entre pods.

---

### ğŸ¯ PERGUNTAS SOBRE KUBERNETES

**Pergunta 7: Mecanismos de Alta Disponibilidade em Kubernetes**

Assuma um serviÃ§o composto por uma aplicaÃ§Ã£o web e uma base de dados instalado num Ãºnico servidor. Discuta que mecanismos da tecnologia Kubernetes podem ajudar na tarefa de garantir alta disponibilidade (HA), e se esses mecanismos sÃ£o suficientes por si sÃ³. Justifique.

**Resposta:**

**Mecanismos do Kubernetes para HA:**

1. **ReplicaÃ§Ã£o de Pods (Deployments)**
   - Cria mÃºltiplas rÃ©plicas do servidor web
   - Se um pod falha, o Kubernetes cria automaticamente outro
   - Exemplo: `replicas: 3` garante sempre 3 instÃ¢ncias ativas

2. **Auto-reparaÃ§Ã£o (Self-healing)**
   - Se um pod ou nÃ³ falha, o Kubernetes detecta e substitui automaticamente
   - Monitora a saÃºde dos contentores continuamente

3. **Balanceamento de Carga (Service)**
   - Um serviÃ§o Kubernetes distribui o trÃ¡fego entre as rÃ©plicas
   - Os clientes contactam o serviÃ§o, nÃ£o os pods individuais

4. **Multi-nÃ³ (Cluster Kubernetes)**
   - Os pods podem ser distribuÃ­dos por vÃ¡rios nÃ³s fÃ­sicos
   - Se um nÃ³ falha, os pods sÃ£o re-agendados noutro nÃ³

**LimitaÃ§Ãµes - NÃ£o sÃ£o suficientes por si sÃ³:**

A base de dados Ã© o problema crÃ­tico. Kubernetes replica o servidor web (stateless), mas a base de dados Ã© stateful. Replicar apenas o contentor da BD nÃ£o garante HA porque:
- Os dados precisam estar sincronizados entre rÃ©plicas (replicaÃ§Ã£o de dados)
- Precisa-se de eleiÃ§Ã£o de lÃ­der em caso de falha
- NecessÃ¡rio armazenamento persistente com high availability prÃ³prio

**SoluÃ§Ã£o Completa:**
1. Kubernetes para a aplicaÃ§Ã£o web (replicas, auto-reparaÃ§Ã£o)
2. Sistema de BD distribuÃ­do (PostgreSQL com Patroni, MySQL com Galera Cluster, etc.)
3. Armazenamento persistente de HA (ex: Kubernetes Persistent Volumes com backing de NFS HA ou cloud storage)

---

**Pergunta 8: ReplicaÃ§Ã£o em ServiÃ§os Multi-camada**

A complexidade da replicaÃ§Ã£o de um serviÃ§o multi-camada nÃ£o varia de acordo com o componente alvo (ex: servidor web, servidor aplicacional, base de dados) a replicar. Concorda ou nÃ£o com esta afirmaÃ§Ã£o? Justifique.

**Resposta:**
**Discordo completamente.** A complexidade varia significativamente consoante o tipo de componente:

**Servidor Web (Stateless) - Baixa Complexidade**
- Sem estado: cada pedido Ã© independente
- ReplicaÃ§Ã£o simples: criar mÃºltiplas instÃ¢ncias
- SincronizaÃ§Ã£o: nÃ£o necessÃ¡ria
- Exemplo: Nginx com 10 rÃ©plicas Ã© trivial

**Servidor Aplicacional (Potencialmente Stateless) - Complexidade MÃ©dia**
- Pode ter cache local ou sessÃµes
- NecessÃ¡rio armazenamento distribuÃ­do para estado compartilhado
- Exemplo: Node.js com sessÃµes em Redis

**Base de Dados (Stateful) - Muito Alta Complexidade**
- Todos os dados devem estar consistentes entre rÃ©plicas
- Problemas: escrita distribuÃ­da, consenso, particionamento
- ReplicaÃ§Ã£o sÃ­ncrona vs. assÃ­ncrona (trade-offs)
- EleiÃ§Ã£o de lÃ­der em caso de falha
- Exemplo: PostgreSQL com replicaÃ§Ã£o Ã© exponencialmente mais complexo que nginx

**ConclusÃ£o**: Replicar Ã© trivial para componentes stateless, mas extremamente complexo para stateful.

---

**Pergunta 9: Elasticidade em Ambientes PaaS**

Diga o que entende por elasticidade de um serviÃ§o a correr num ambiente de computaÃ§Ã£o em nuvem. Em que medida Ã© que uma arquitetura PaaS contribui para a atingir? Justifique.

**Resposta:**

**DefiniÃ§Ã£o de Elasticidade:**
Capacidade de um sistema aumentar ou diminuir automaticamente os seus recursos (CPU, memÃ³ria, instÃ¢ncias) em resposta Ã s flutuaÃ§Ãµes de carga, sem intervenÃ§Ã£o manual. Objetivo: otimizar desempenho e custos.

**Como PaaS contribui para Elasticidade:**

1. **AbstraÃ§Ã£o de Infraestrutura**
   - O programador foca-se no cÃ³digo, nÃ£o na gestÃ£o de servidores
   - A plataforma cuida do provisionamento automÃ¡tico
   - Exemplo: Google App Engine â€“ especifica-se apenas o cÃ³digo e a carga Ã© gerada automaticamente

2. **Auto-scaling AutomÃ¡tico**
   - PaaS monitora mÃ©tricas (CPU, trÃ¡fego) e ajusta automaticamente
   - Exemplos: App Engine, Heroku
   - Baseado em polÃ­ticas definidas (e.g., "se CPU > 70%, adicione uma instÃ¢ncia")

3. **Billing por Uso Real**
   - Paga-se apenas pelo que se usa
   - Ao escalar up, custos aumentam; ao escalar down, custos diminuem
   - Incentivo econÃ³mico para elasticidade

4. **Modelos de Dados DistribuÃ­dos**
   - PaaS fornece bases de dados escalÃ¡veis (ex: Firebase, Amazon DynamoDB)
   - Dados sÃ£o particionados automaticamente

**DiferenÃ§a com IaaS:**
- **IaaS**: Escalabilidade manual (criar VMs manualmente)
- **PaaS**: Elasticidade automÃ¡tica (plataforma decide quando escalar)

---

## 25. Storage

### Desafios Fundamentais

O armazenamento em sistemas distribuÃ­dos enfrenta desafios Ãºnicos:
1. **ReplicaÃ§Ã£o**: Manter dados consistentes entre mÃºltiplos nÃ³s
2. **TolerÃ¢ncia a Falhas**: Sobreviver a falhas de nÃ³s, discos
3. **Escalabilidade**: Gerenciar volumes crescentes de dados
4. **EficiÃªncia**: Otimizar para latÃªncia vs. throughput vs. espaÃ§o

### 25.7 Disponibilidade: ReplicaÃ§Ã£o vs Erasure Coding

**ReplicaÃ§Ã£o**: MÃºltiplas cÃ³pias exatas. Overhead 3x, tolerÃ¢ncia a 2 falhas, leitura rÃ¡pida.

**Erasure Codes**: Dados divididos em k fragmentos + m blocos de paridade. Overhead 1.5x, tolerÃ¢ncia a 3 falhas, leitura requer reconstruÃ§Ã£o.

**Quando Usar:**
- **ReplicaÃ§Ã£o**: Dados "quentes", requisitos de baixa latÃªncia
- **Erasure Codes**: Dados "frios", grandes volumes, baixo custo

---

### ğŸ¯ PERGUNTAS SOBRE ARMAZENAMENTO

**Pergunta 10: SeparaÃ§Ã£o de Dados e Metadados**

Em vÃ¡rios sistemas de armazenamento distribuÃ­dos, a gestÃ£o de dados e metadados Ã© feita por componentes diferentes. Explique a vantagem de considerar componentes independentes para gestÃ£o de dados e metadados. Justifique.

**Resposta:**

**DefiniÃ§Ã£o:**
- **Dados**: O conteÃºdo real dos ficheiros
- **Metadados**: InformaÃ§Ãµes sobre ficheiros (localizaÃ§Ã£o, tamanho, permissÃµes, proprietÃ¡rio)

**Arquitetura Separada (Ex: HDFS)**
- **Metadata Servers**: Gerem o namespace de ficheiros, permissÃµes, localizaÃ§Ã£o de blocos
- **Data Nodes**: Armazenam apenas os blocos de dados

**Vantagens da SeparaÃ§Ã£o:**

1. **Escalabilidade Diferenciada**
   - Metadados sÃ£o pequenos, cabem em memÃ³ria
   - Dados sÃ£o volumosos, requerem armazenamento de bloco
   - Exemplo: 1 terabyte de dados Ã© apenas alguns GB de metadados
   - Podem escalar independentemente

2. **OtimizaÃ§Ã£o de Recursos**
   - Metadata Servers: MÃ¡quinas com muita RAM, CPUs moderadas (acesso rÃ¡pido)
   - Data Nodes: MÃ¡quinas com muita capacidade de armazenamento
   - NÃ£o desperdiÃ§ar recursos

3. **GestÃ£o de TransaÃ§Ãµes Facilitada**
   - OperaÃ§Ãµes de metadados sÃ£o atÃ³micas e centralizadas
   - Dados podem ser replicados assincronamente
   - Evita inconsistÃªncia (um ficheiro nÃ£o pode estar em dois locais diferentes)

4. **TolerÃ¢ncia a Falhas**
   - Falha de um Data Node: apenas esse bloco Ã© perdido, metadados intactos
   - Falha de Metadata Server: todo o sistema falha (necessÃ¡rio replicar Metadata Servers)

**Exemplo Real (HDFS):**
```
Cliente quer ler /user/data/file.txt
1. Contacta Metadata Server: "Onde estÃ¡ file.txt?"
   Resposta: Blocos [1,2,3] estÃ£o nos Data Nodes [A, B, C]
2. Contacta Data Nodes A, B, C para obter os blocos
```

---

**Pergunta 11: ReplicaÃ§Ã£o vs Erasure Codes em Armazenamento**

Compare os mecanismos de replicaÃ§Ã£o e erasure codes para garantir a disponibilidade de dados em sistemas de armazenamento distribuÃ­do. Qual Ã© mais apropriado em diferentes contextos?

**Resposta:**

| Aspeto | ReplicaÃ§Ã£o | Erasure Codes |
|--------|-----------|---------------|
| **Conceito** | CÃ³pias exatas dos dados | Dados divididos em fragmentos + paridade |
| **Overhead** | 3x (exemplo: 3 cÃ³pias) | 1.5x (exemplo: k=6, m=3) |
| **TolerÃ¢ncia a Falhas** | 2 falhas (com 3 cÃ³pias) | 3 falhas (com k=6, m=3) |
| **LatÃªncia de Leitura** | Imediata | Necessita reconstruÃ§Ã£o |
| **LatÃªncia de Escrita** | SÃ­ncrona (replicaÃ§Ã£o completa) | Mais rÃ¡pida |

**ReplicaÃ§Ã£o Ã© Apropriada Para:**
- Dados "quentes" (acesso frequente)
- Requisitos de baixa latÃªncia
- Exemplo: Cache, base de dados ativa
- Tradeoff: Custo vs. Performance

**Erasure Codes sÃ£o Apropriados Para:**
- Dados "frios" (acesso raro, arquivo)
- Grandes volumes onde economia de espaÃ§o Ã© crÃ­tica
- Exemplo: Amazon Glacier, backups de longa duraÃ§Ã£o
- Tradeoff: EspaÃ§o vs. Performance

**DecisÃ£o PrÃ¡tica:**
- HDFS usa replicaÃ§Ã£o para dados primÃ¡rios (performance)
- Glacier usa erasure codes para arquivo (economia)

---

**Pergunta 12: TÃ©cnicas de OtimizaÃ§Ã£o de Armazenamento**

Para um sistema de armazenamento que tem como principais propÃ³sitos garantir alta disponibilidade e simultaneamente reduzir o espaÃ§o ocupado pelos dados persistidos, quais funcionalidades sugeria? Justifique.

**Resposta:**

**CombinaÃ§Ã£o Recomendada:**

1. **Erasure Codes (em vez de ReplicaÃ§Ã£o)**
   - Reduz overhead de 3x para 1.5x
   - MantÃ©m tolerÃ¢ncia a 3+ falhas simultÃ¢neas
   - JustificaÃ§Ã£o: Melhor relaÃ§Ã£o espaÃ§o/disponibilidade

2. **CompressÃ£o**
   - Reduz tamanho dos dados em disco
   - Tipos: GZIP (bom), SNAPPY (rÃ¡pido), LZMA (mÃ¡xima compressÃ£o)
   - Tradeoff: CPU vs. EspaÃ§o
   - JustificaÃ§Ã£o: ReduÃ§Ã£o imediata de espaÃ§o

3. **DeduplicaÃ§Ã£o**
   - Elimina cÃ³pias redundantes de dados entre ficheiros
   - Exemplo: Se 1000 utilizadores tÃªm a mesma foto, apenas 1 cÃ³pia no disco
   - Tradeoff: CPU para detecÃ§Ã£o vs. EspaÃ§o poupado
   - JustificaÃ§Ã£o: Muito efetivo para dados altamente redundantes

4. **Tiering (Camadas)**
   - Dados quentes: ReplicaÃ§Ã£o em SSD (rÃ¡pido)
   - Dados mornos: Erasure codes em HDD (equilibrado)
   - Dados frios: Arquivo comprimido em tape (barato)
   - JustificaÃ§Ã£o: Otimizar custo-benefÃ­cio conforme padrÃ£o de acesso

**SoluÃ§Ã£o Completa Recomendada:**
```
Alta Disponibilidade + EficiÃªncia EspaÃ§o:
â†’ Erasure Codes (k=8, m=4) para tolerÃ¢ncia a falhas
+ CompressÃ£o SNAPPY (bom balanÃ§o CPU/espaÃ§o)
+ DeduplicaÃ§Ã£o para ficheiros comuns
```

---

## 17. Ansible (resumo)

### MotivaÃ§Ã£o: AutomatizaÃ§Ã£o de Infraestrutura

A gestÃ£o manual de mÃºltiplos servidores Ã© impraticÃ¡vel.

**Paradigma Imperativo (Shell Script):**
```bash
#!/bin/sh
apt-get update
apt-get install -y nginx
cp myconfig.conf /etc/nginx/
systemctl restart nginx
```
- Define **como** fazer algo (passo a passo)
- NÃ£o idempotente: Correr 2x pode falhar

**Paradigma Declarativo (Ansible):**
```yaml
hosts: webservers
tasks:
  - name: Install Nginx
    apt:
      name: nginx
      state: present
```
- Define **o que** queremos (estado final)
- Idempotente: Correr 2x tem o mesmo resultado

---

### ğŸ¯ PERGUNTAS SOBRE ANSIBLE E PROVISIONAMENTO

**Pergunta 13: DiferenÃ§a entre Provisionamento e Deployment**

Defina o que entende por provisioning (provisionamento) e deployment de uma aplicaÃ§Ã£o. Qual Ã© o objetivo de cada um?

**Resposta:**

**Provisionamento (Provisioning):**
- **DefiniÃ§Ã£o**: A aÃ§Ã£o de fornecer ou disponibilizar recursos de infraestrutura para utilizaÃ§Ã£o
- **Escopo**: Servidores, armazenamento, rede, VMs, utilizadores
- **Objetivo**: Preparar a infraestrutura (hardware, SO, dependÃªncias) antes de instalar a aplicaÃ§Ã£o
- **Exemplo**: Criar uma VM, instalar Python, instalar PostgreSQL, configurar firewall
- **Responsabilidade**: Tipicamente das operaÃ§Ãµes (Ops)

**Deployment:**
- **DefiniÃ§Ã£o**: O processo de instalar ou atualizar uma aplicaÃ§Ã£o/serviÃ§o num servidor
- **Escopo**: CÃ³digo da aplicaÃ§Ã£o, configuraÃ§Ã£o especÃ­fica da app
- **Objetivo**: Colocar o cÃ³digo em execuÃ§Ã£o num servidor jÃ¡ provisionado
- **Exemplo**: Fazer `git clone`, correr migraÃ§Ãµes BD, iniciar servidor web
- **Responsabilidade**: Tipicamente do desenvolvimento (Dev)

**RelaÃ§Ã£o:**
Provisionamento â†’ Deployment
1. Primeiro, provisiona-se a infraestrutura
2. Depois, faz-se deploy da aplicaÃ§Ã£o

**Na PrÃ¡tica DevOps:**
Ambos estÃ£o automatizados em cÃ³digo (IaC - Infrastructure as Code), unindo Dev + Ops.

---

**Pergunta 14: Vantagens da AutomaÃ§Ã£o com Ansible**

No guiÃ£o das aulas prÃ¡ticas, foram criados diferentes roles para facilitar a instalaÃ§Ã£o automÃ¡tica da aplicaÃ§Ã£o Swap usando Ansible. Qual Ã© a funÃ§Ã£o dos roles num playbook Ansible? De que forma os roles contribuem para um melhor aprovisionamento de aplicaÃ§Ãµes? Justifique.

**Resposta:**

**FunÃ§Ã£o dos Roles:**
Um role Ã© um componente reutilizÃ¡vel que encapsula todas as configuraÃ§Ãµes e tarefas para uma funcionalidade especÃ­fica.

**Estrutura de um Role:**
```
roles/
â””â”€â”€ nginx/
    â”œâ”€â”€ tasks/
    â”‚   â””â”€â”€ main.yml        (tarefas: instalar, configurar)
    â”œâ”€â”€ handlers/
    â”‚   â””â”€â”€ main.yml        (reiniciar serviÃ§o se mudou config)
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ nginx.conf.j2   (ficheiro de config dinÃ¢mico)
    â”œâ”€â”€ files/
    â”‚   â””â”€â”€ default.html    (ficheiros estÃ¡ticos)
    â””â”€â”€ vars/
        â””â”€â”€ main.yml        (variÃ¡veis do role)
```

**ContribuiÃ§Ãµes para Melhor Aprovisionamento:**

1. **ReutilizaÃ§Ã£o e Modularidade**
   - Role `nginx` pode ser usado em mÃºltiplos playbooks
   - NÃ£o duplicar cÃ³digo
   - Exemplo: Instalar Nginx em 3 projetos diferentes

2. **OrganizaÃ§Ã£o Clara**
   - SeparaÃ§Ã£o de preocupaÃ§Ãµes (tasks, handlers, templates)
   - FÃ¡cil de compreender e manter
   - DocumentaÃ§Ã£o natural da infraestrutura

3. **ComposiÃ§Ã£o Simples**
   ```yaml
   hosts: webservers
   roles:
     - common          # ConfiguraÃ§Ã£o base (SO, packages)
     - users           # Criar utilizadores
     - ssh-server      # Configurar SSH
     - nginx           # Instalar e configurar Nginx
   ```
   - Ler este playbook Ã© trivial
   - Compreende-se exatamente o que Ã© instalado

4. **ConsistÃªncia e Repetibilidade**
   - Mesmo role garante sempre o mesmo resultado
   - IdempotÃªncia: Correr 2x tem o mesmo efeito que correr 1x
   - Infraestrutura previsÃ­vel

5. **Escalabilidade**
   - Adicionar novos servidores Ã© trivial: aplicar os mesmos roles
   - Exemplo prÃ¡tico no Swap: Role garante que nova instÃ¢ncia Ã© idÃªntica

---

**Pergunta 15: Paradigma Imperativo vs Declarativo**

Compare a abordagem imperativa (shell scripts tradicional) com a abordagem declarativa (Ansible playbooks). Quais sÃ£o as implicaÃ§Ãµes para a gestÃ£o de configuraÃ§Ã£o em infraestruturas complexas?

**Resposta:**

**Abordagem Imperativa (Shell Script):**
```bash
#!/bin/sh
apt-get update
apt-get install -y nginx
cp myconfig.conf /etc/nginx/
systemctl restart nginx
```
- Define **como** fazer algo (passo a passo)
- Cada linha Ã© um comando a executar

**Problemas:**
- **NÃ£o Idempotente**: Correr 2x pode falhar (ex: se package jÃ¡ instalado)
- **FrÃ¡gil**: Se script falha a meio, estado fica inconsistente
- **DifÃ­cil Diagnosticar**: Qual passo falhou?

**Abordagem Declarativa (Ansible):**
```yaml
hosts: webservers
tasks:
  - name: Install Nginx
    apt:
      name: nginx
      state: present
  - name: Copy config
    template:
      src: nginx.conf.j2
      dest: /etc/nginx/nginx.conf
    notify: restart nginx
  
  handlers:
    - name: restart nginx
      service:
        name: nginx
        state: restarted
```
- Define **o que** queremos (estado final desejado)
- Ansible garante que o sistema atinge esse estado

**Vantagens:**
- **Idempotente**: Correr 2x tem o mesmo resultado
- **Robusto**: Apenas efetua mudanÃ§as se necessÃ¡rio
- **Diagnostico Claro**: Sabe-se exatamente qual task falhou

**ImplicaÃ§Ãµes em Infraestruturas Complexas:**

1. **Drift Configuracional**
   - Imperativo: Se alguÃ©m modifica manualmente um ficheiro, o script nÃ£o consegue repor
   - Declarativo: PrÃ³xima execuÃ§Ã£o repÃµe Ã  configuraÃ§Ã£o desejada

2. **RecuperaÃ§Ã£o de Falhas**
   - Imperativo: NecessÃ¡rio refazer tudo
   - Declarativo: Reexecutar o playbook corrige

3. **DocumentaÃ§Ã£o Viva**
   - Imperativo: CÃ³digo Ã© preto-branco, pouca documentaÃ§Ã£o
   - Declarativo: YAML Ã© legÃ­vel por humanos, descreve o estado desejado

4. **Versioning**
   - Imperativo: Scripts mudam, difÃ­cil rastrear versions
   - Declarativo: Playbooks em Git, histÃ³rico completo de mudanÃ§as

---

## 9. DevOps

**DevOps: Mais que Uma Ferramenta, Uma Filosofia**

DevOps Ã© a sÃ­ntese cultural e tÃ©cnica que une Desenvolvimento (Dev) e OperaÃ§Ãµes (Ops), rompendo os silos tradicionais entre estas equipas.

**Objetivo Central de DevOps:**
Entregar valor aos utilizadores de forma mais rÃ¡pida e fiÃ¡vel, suportando mudanÃ§as pequenas, rÃ¡pidas e frequentes.

**Antes de DevOps (Modelo Tradicional):**
```
Dev Team                     Ops Team
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Write Code   â”‚ â”€ Weeks â†’ â”‚ Deploy       â”‚
â”‚ Test Locally â”‚            â”‚ (Manual)     â”‚
â”‚ Release      â”‚            â”‚ Run in Prod  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â†“                              â†“
   RÃ¡pido                      Lento
   Ãgil                        Conservador
   Quer mudar                  Quer estabilidade
   
   CONFLITO: Dev quer velocidade, Ops quer fiabilidade
```

**Com DevOps (Modelo Integrado):**
RÃ¡pido, FiÃ¡vel, Iterativo

---

### ğŸ¯ PERGUNTAS SOBRE DEVOPS

**Pergunta 23: DevOps como SÃ­ntese de Desenvolvimento e OperaÃ§Ãµes**

Defina o que entende por DevOps e explique como a Infraestrutura como CÃ³digo (IaC) Ã© fundamental para alcanÃ§ar os objetivos de DevOps. DÃª um exemplo prÃ¡tico.

**Resposta:**

**DevOps: Mais que Uma Ferramenta, Uma Filosofia**

DevOps Ã© a sÃ­ntese cultural e tÃ©cnica que une Desenvolvimento (Dev) e OperaÃ§Ãµes (Ops), rompendo os silos tradicionais entre estas equipas.

**Objetivo Central de DevOps:**
Entregar valor aos utilizadores de forma mais rÃ¡pida e fiÃ¡vel, suportando mudanÃ§as pequenas, rÃ¡pidas e frequentes.

**Infraestrutura como CÃ³digo (IaC): A Ponte TÃ©cnica**

Antes de IaC, provisionamento era manual e ad-hoc:
```
Ops Engineer 1: "Criar um servidor Ubuntu com Nginx"
Ops Engineer 2: Pede instruÃ§Ãµes verbalmente
Resultado: Dois servidores ligeiramente diferentes (configuration drift)
```

Com IaC, infraestrutura Ã© definida em cÃ³digo versionado.

**BenefÃ­cios de IaC para DevOps:**

1. **Reprodutibilidade**: Mesmo cÃ³digo = Mesmo resultado. Dev e Prod sÃ£o idÃªnticos.
2. **Versionamento**: Infraestrutura estÃ¡ em Git. HistÃ³rico completo de mudanÃ§as.
3. **AutomatizaÃ§Ã£o Completa**: `git push` â†’ CI/CD pipeline â†’ Deploy automÃ¡tico
4. **DocumentaÃ§Ã£o Viva**: O cÃ³digo Ã© a documentaÃ§Ã£o

**Exemplo PrÃ¡tico Completo:**

CenÃ¡rio: Startup com aplicaÃ§Ã£o Node.js precisa escalar de 1 para 10 servidores

**Sem DevOps/IaC (Tradicional):**
1. Engenheiro criar manualmente 9 novos servidores
2. Instalar Node.js, npm, dependÃªncias (pode falhar, variaÃ§Ãµes)
3. Configurar load balancer (manual)
4. DocumentaÃ§Ã£o? NÃ£o existe...
5. Tempo: 3-5 dias
6. Taxa de erro: Alta

**Com DevOps/IaC:**
1. Engenheiro modifica cÃ³digo IaC: `instance_count = 10`
2. Faz `git push`
3. CI/CD pipeline:
   - Valida cÃ³digo IaC
   - Cria 9 novos servidores
   - Instala software (automaticamente)
   - Testa connectivity
   - Atualiza load balancer (automaticamente)
4. Monitoring detecta status de todos
5. Tempo: 5-10 minutos
6. Taxa de erro: Praticamente zero
7. Infraestrutura documentada em Git (histÃ³rico completo)

---

**Pergunta 24: Ciclo de Feedback em DevOps**

Descreva o ciclo iterativo de DevOps (Plan â†’ Code â†’ Build â†’ Test â†’ Deploy â†’ Operate â†’ Monitor â†’ Feedback â†’ Plan...). Como Ã© que cada fase contribui para alcanÃ§ar maior velocidade e fiabilidade?

**Resposta:**

**O Ciclo ContÃ­nuo DevOps:**

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  PLAN: Definir requisitos   â”‚
           â”‚  (Features, bugs, configs)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  CODE: Desenvolvimento      â”‚
           â”‚  (Git commit, merge)        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  BUILD: Construir artefato  â”‚
           â”‚  (Compilar, package)        â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  TEST: ValidaÃ§Ã£o automÃ¡tica â”‚
           â”‚  (Unit, integration, perf)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  DEPLOY: LanÃ§amento          â”‚
           â”‚  (Staging â†’ Production)     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  OPERATE: Executar e gerir  â”‚
           â”‚  (Escalabilidade, recursos) â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  MONITOR: Observar sistema  â”‚
           â”‚  (MÃ©tricas, logs, alertas)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  FEEDBACK: AnÃ¡lise de dados â”‚
           â”‚  (Incidentes, performance)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
           (Voltar a PLAN com insights)
```

**Cada Fase Contribui Para:**

**PLAN:**
- **Objetivo**: Definir claramente o que se vai fazer
- **BenefÃ­cio de Velocidade**: Evitar retrabalho
- **BenefÃ­cio de Fiabilidade**: Compreender requisitos reduz bugs

**CODE:**
- **Objetivo**: Implementar a feature/fix
- **BenefÃ­cio de Velocidade**: Developers trabalham em paralelo em branches
- **BenefÃ­cio de Fiabilidade**: Code review, pair programming

**BUILD:**
- **Objetivo**: Criar artefato executÃ¡vel (ex: Docker image)
- **BenefÃ­cio de Velocidade**: AutomÃ¡tico, <5 minutos
- **BenefÃ­cio de Fiabilidade**: Mesmo artefato em todos os ambientes (Dev/Staging/Prod)

**TEST:**
- **Objetivo**: Validar antes de ir Ã  produÃ§Ã£o
- **BenefÃ­cio de Velocidade**: Feedback automÃ¡tico em minutos
- **BenefÃ­cio de Fiabilidade**: Testes unitÃ¡rios, integraÃ§Ã£o, performance previnem bugs

**DEPLOY:**
- **Objetivo**: Colocar em produÃ§Ã£o
- **BenefÃ­cio de Velocidade**: AutomÃ¡tico (blue-green deploy, canary deploy)
- **BenefÃ­cio de Fiabilidade**: Rollback automÃ¡tico se algo falha

**OPERATE:**
- **Objetivo**: Manter sistema em produÃ§Ã£o
- **BenefÃ­cio de Velocidade**: Auto-scaling, orquestraÃ§Ã£o automÃ¡tica
- **BenefÃ­cio de Fiabilidade**: Infraestrutura como cÃ³digo garante consistÃªncia

**MONITOR:**
- **Objetivo**: Observar comportamento em tempo real
- **BenefÃ­cio de Velocidade**: Detetar problemas rÃ¡pido
- **BenefÃ­cio de Fiabilidade**: Alertas automÃ¡ticos, correlaÃ§Ã£o de eventos

**FEEDBACK:**
- **Objetivo**: Aprender com dados reais de produÃ§Ã£o
- **BenefÃ­cio de Velocidade**: Priorizir prÃ³ximas features baseado em dados
- **BenefÃ­cio de Fiabilidade**: Incidentes informam melhorias arquiteturais

---

## 26. MonitorizaÃ§Ã£o

### FundamentaÃ§Ã£o TeÃ³rica

Sistemas modernos sÃ£o "caixas negras" que geram milhÃµes de eventos por segundo. A monitorizaÃ§Ã£o transforma "ruÃ­do" em "sinal".

### 26.4 Modelo arquitetural em camadas

**Os Quatro Componentes (Bottom-up):**

1. **ObservaÃ§Ã£o**: Recolhe eventos brutos do sistema
   - TÃ©cnicas: ObservaÃ§Ã£o passiva (sniffing), instrumentaÃ§Ã£o, sondagem
   - **Problema**: Gera milhÃµes de eventos/s, inÃºteis por si sÃ³

2. **Recolha**: Agrega e normaliza os eventos observados
   - Sincroniza timestamps de mÃºltiplos sistemas
   - Oferece armazenamento temporÃ¡rio
   - Modelos: Push (eventos enviados ativamente) ou Pull (recolhidos periodicamente)
   - **Problema**: Ainda sÃ£o dados brutos

3. **AnÃ¡lise**: Transforma dados brutos em informaÃ§Ã£o
   - Armazenamento eficiente (indexaÃ§Ã£o)
   - Processamento: Filtrar, consultar, sumarizar
   - Tecnologias: Elasticsearch, Prometheus, InfluxDB
   - **Resultado**: InformaÃ§Ã£o estruturada

4. **ApresentaÃ§Ã£o**: Torna a informaÃ§Ã£o visÃ­vel e compreensÃ­vel
   - Formatos: Dashboards (tempo real), RelatÃ³rios, Alarmes
   - Ferramentas: Kibana (com Elasticsearch), Grafana
   - **Resultado**: Insights acionÃ¡veis

---

### ğŸ¯ PERGUNTAS SOBRE MONITORIZAÃ‡ÃƒO

**Pergunta 16: A IlusÃ£o das MÃ©dias em MonitorizaÃ§Ã£o**

A utilizaÃ§Ã£o incorreta de mÃ©tricas de desempenho, especialmente focando apenas em mÃ©dias, pode levar a conclusÃµes errÃ³neas sobre a qualidade de um serviÃ§o. Concorda? Justifique com exemplos de padrÃµes problemÃ¡ticos que as mÃ©dias escondem.

**Resposta:**
**Concordo completamente.** As mÃ©dias sÃ£o enganadoras e escondem problemas crÃ­ticos.

**Exemplo CrÃ­tico:**
TrÃªs servidores web tÃªm estas latÃªncias (em ms):
- Servidor A: [50, 50, 50, 50, 50] â†’ MÃ©dia = 50ms
- Servidor B: [10, 10, 10, 10, 200] â†’ MÃ©dia = 48ms
- Servidor C: [1, 1, 1, 1, 1] â†’ MÃ©dia = 1ms

A olhar apenas Ã s mÃ©dias, Servidor B parece melhor que A! Mas um em cada 5 pedidos Ã© extremamente lento.

**PadrÃµes ProblemÃ¡ticos que as MÃ©dias Escondem:**

1. **DistribuiÃ§Ã£o de Cauda Longa (Long Tail)**
   - 99% dos pedidos sÃ£o rÃ¡pidos (20ms)
   - 1% dos pedidos sÃ£o muito lentos (5000ms)
   - MÃ©dia: ~70ms (enganadora)
   - **Problema Real**: Utilizadores experimentam ocasionalmente despensa gritante
   - **Causa**: Pausas de Garbage Collection, cache misses, timeouts de rede

2. **DegradaÃ§Ã£o ao Longo do Tempo**
   - Primeiros 1000 pedidos: 50ms cada
   - PrÃ³ximos 1000 pedidos: 100ms cada
   - PrÃ³ximos 1000 pedidos: 500ms cada
   - MÃ©dia: 216ms
   - **Problema Real**: Sistema degrada ao longo do tempo
   - **Causa**: Memory leak, acumulaÃ§Ã£o de conexÃµes, etc.

3. **Bimodalidade (Dois Modos)**
   - Cache hit: 5ms
   - Cache miss: 200ms
   - MÃ©dia: 100ms
   - **Problema Real**: Comportamento completamente diferente consoante cache
   - **SoluÃ§Ã£o**: Entender a distribuiÃ§Ã£o e otimizar taxa de hits

**MÃ©tricas Corretas a Usar:**

1. **Percentis (P50, P95, P99)**
   - P99: Tempo para 99% dos pedidos
   - Mais representativo que mÃ©dia

2. **Desvio PadrÃ£o / VariÃ¢ncia**
   - Mostra a dispersÃ£o dos dados

3. **VisualizaÃ§Ãµes**
   - ECDF (Empirical Cumulative Distribution Function)
   - Histogramas

---

**Pergunta 17: Compromissos no Design de Monitores**

A forma como um monitor Ã© desenhado implica compromissos (trade-offs) importantes. Discuta o compromisso entre "observaÃ§Ã£o orientada a eventos" vs "amostragem" na monitorizaÃ§Ã£o de um sistema. Qual escolher em diferentes contextos?

**Resposta:**

**ObservaÃ§Ã£o Orientada a Eventos (Event-driven):**
- A observaÃ§Ã£o Ã© despoletada sempre que um evento de interesse ocorre
- Captura todos os eventos relevantes

**Amostragem (Sampling):**
- A observaÃ§Ã£o ocorre apenas periodicamente (ex: a cada 10ms)
- Captura uma amostra dos eventos

**Compromisso: PrecisÃ£o vs. Overhead de Performance**

| Aspeto | Orientada a Eventos | Amostragem |
|--------|-------------------|-----------|
| **PrecisÃ£o** | 100% (nenhum evento perdido) | Parcial (alguns eventos perdidos) |
| **Overhead** | Muito alto (monitor Ã© chamado constantemente) | Baixo (apenas a intervalos) |
| **Impacto Sistema** | DegradaÃ§Ã£o significativa do desempenho | NegligenciÃ¡vel |

**Exemplo PrÃ¡tico:**
Monitorizar operaÃ§Ãµes de disco:
- **Event-driven**: Cada read/write dispara uma observaÃ§Ã£o
  - Em alta carga: 100.000 operaÃ§Ãµes/s â†’ 100.000 observaÃ§Ãµes/s
  - Overhead: 50% da CPU pode ser gasto em monitoring!
  - Problema: O prÃ³prio monitor faz o sistema mais lento

- **Amostragem**: A cada 1ms, sample 10 operaÃ§Ãµes
  - Mesmo em alta carga: 1.000 observaÃ§Ãµes/s
  - Overhead: <1% da CPU
  - Desvantagem: Pode-se perder picos raros (ex: uma operaÃ§Ã£o de 10s)

**Contextos Apropriados:**

1. **Usar Event-driven:**
   - Sistemas crÃ­ticos com carga baixa-mÃ©dia
   - Necessidade de detetar anomalias raras
   - Exemplo: Monitorizar falhas de seguranÃ§a
   - Overhead aceitÃ¡vel

2. **Usar Amostragem:**
   - Sistemas de alta performance
   - AnÃ¡lise de tendÃªncias (nÃ£o necessita precisÃ£o 100%)
   - Exemplo: Monitorizar latÃªncia de aplicaÃ§Ã£o web em produÃ§Ã£o

**SoluÃ§Ã£o PrÃ¡tica Comum:**
Implementar ambos:
- **Event-driven** para eventos crÃ­ticos (erros, falhas)
- **Amostragem** para mÃ©tricas contÃ­nuas (CPU, memÃ³ria)

---

**Pergunta 18: Componentes de um Ciclo de MonitorizaÃ§Ã£o Completo**

Descreva os quatro componentes essenciais de uma arquitetura de monitorizaÃ§Ã£o moderna. Explique como cada um contribui para a transformaÃ§Ã£o de "ruÃ­do" (eventos brutos) em "sinal" (informaÃ§Ã£o acionÃ¡vel).

**Resposta:**

**Os Quatro Componentes (Bottom-up):**

1. **ObservaÃ§Ã£o**: Recolhe eventos brutos do sistema
   - TÃ©cnicas: ObservaÃ§Ã£o passiva (sniffing), instrumentaÃ§Ã£o, sondagem
   - **Problema**: Gera milhÃµes de eventos/s, inÃºteis por si sÃ³

2. **Recolha**: Agrega e normaliza os eventos observados
   - Sincroniza timestamps de mÃºltiplos sistemas
   - Oferece armazenamento temporÃ¡rio
   - Modelos: Push ou Pull
   - **Problema**: Ainda sÃ£o dados brutos

3. **AnÃ¡lise**: Transforma dados brutos em informaÃ§Ã£o
   - Armazenamento eficiente (indexaÃ§Ã£o)
   - Processamento: Filtrar, consultar, sumarizar
   - **Resultado**: InformaÃ§Ã£o estruturada

4. **ApresentaÃ§Ã£o**: Torna a informaÃ§Ã£o visÃ­vel e compreensÃ­vel
   - Formatos: Dashboards, RelatÃ³rios, Alarmes
   - **Resultado**: Insights acionÃ¡veis

**TransformaÃ§Ã£o RuÃ­do â†’ Sinal (Exemplo PrÃ¡tico):**

```
RuÃ­do (ObservaÃ§Ã£o):
â†’ 1000 log entries por segundo
â†’ "User login attempt from 192.168.1.1"
â†’ "User login attempt from 192.168.1.1"
â†’ "User login attempt from 192.168.1.1"
(PadrÃ£o invisÃ­vel)

â†“ Recolha
(NormalizaÃ§Ã£o de timestamps)

â†“ AnÃ¡lise
(AgregaÃ§Ã£o): "192.168.1.1 teve 100 tentativas de login em 1 segundo"

â†“ ApresentaÃ§Ã£o
Sinal (Insight AcionÃ¡vel):
â†’ Alert: "PossÃ­vel ataque brute-force de 192.168.1.1"
â†’ AÃ§Ã£o: Bloquear IP
```

---

## 12. Arquiteturas distribuÃ­das (padrÃµes)

### PadrÃµes Fundamentais de DistribuiÃ§Ã£o

**1. ReplicaÃ§Ã£o**: MÃºltiplas cÃ³pias idÃªnticas. Para disponibilidade e escalabilidade de leitura.

**2. Particionamento (Sharding)**: Dados/funcionalidade divididos. Para escalabilidade de escrita.

**3. OrientaÃ§Ã£o a ServiÃ§os**: Sistema dividido em serviÃ§os independentes. Para modularidade e escalabilidade.

---

### ğŸ¯ PERGUNTAS SOBRE ARQUITETURAS DISTRIBUÃDAS

**Pergunta 19: PadrÃµes Fundamentais de DistribuiÃ§Ã£o**

Uma arquitetura distribuÃ­da pode implementar trÃªs padrÃµes fundamentais para lidar com escalabilidade e fiabilidade. Indique e explique cada um, dando exemplos de quando cada Ã© apropriado.

**Resposta:**

**PadrÃ£o 1: ReplicaÃ§Ã£o**
- **Conceito**: MÃºltiplas cÃ³pias idÃªnticas da mesma funcionalidade/dados
- **Objetivo**: Disponibilidade e escalabilidade de leitura
- **Como Funciona**: Servidor Master sincroniza com Slaves
- **Exemplos**: RAID, Database replication (MySQL, PostgreSQL)
- **Quando Usar**:
  - Dados sÃ£o lidos frequentemente, escritos raramente
  - NecessÃ¡ria baixa latÃªncia (cÃ³pias locais)
  - Exemplo: CatÃ¡logo de produtos de um e-commerce

**PadrÃ£o 2: Particionamento (Sharding)**
- **Conceito**: Dados/funcionalidade divididos por vÃ¡rios servidores
- **Objetivo**: Escalabilidade de escrita e reduÃ§Ã£o de dados por servidor
- **Exemplos**: MongoDB sharding, Elasticsearch sharding
- **Quando Usar**:
  - Dados muito grandes para um servidor
  - NecessÃ¡ria escalabilidade de escrita
  - Exemplo: Netflix com millions de utilizadores

**PadrÃ£o 3: OrientaÃ§Ã£o a ServiÃ§os**
- **Conceito**: Sistema dividido em mÃºltiplos serviÃ§os independentes
- **EvoluÃ§Ã£o**: MonÃ³lito â†’ DivisÃ£o vertical â†’ MicroserviÃ§os
- **BenefÃ­cios**: Escalabilidade independente, desenvolvimento paralelo, tolerÃ¢ncia a falhas
- **Exemplos**: MicroserviÃ§os (cada um gerido por equipa diferente)
- **Quando Usar**:
  - Grande organizaÃ§Ã£o com mÃºltiplos teams
  - Diferentes partes do sistema tÃªm requisitos distintos
  - Exemplo: Netflix com serviÃ§os de Payment, Streaming, Recommendation, etc.

---

**Pergunta 20: Arquitetura Multi-tier e GestÃ£o de Estado**

Explique a arquitetura multi-tier (3 camadas ou mais) e discuta o desafio do estado nesta arquitetura. Por que Ã© que Ã© mais fÃ¡cil replicar computaÃ§Ã£o stateless do que estado persistente?

**Resposta:**

**Arquitetura Multi-tier Tradicional (3 Camadas):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Presentation      â”‚ (Camada 1: Interface com utilizador)
â”‚  (Web Server)       â”‚ Stateless: Apenas serve HTML/JSON
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application       â”‚ (Camada 2: LÃ³gica de negÃ³cio)
â”‚  (App Server)       â”‚ Potencialmente com estado (cache, sessÃµes)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data              â”‚ (Camada 3: PersistÃªncia)
â”‚  (Database)         â”‚ Sempre com estado (dados persistentes)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**GestÃ£o de Estado em Cada Camada:**

1. **Camada de ApresentaÃ§Ã£o (Stateless)**
   - NÃ£o armazena estado
   - Cada pedido Ã© independente
   - ReplicaÃ§Ã£o: Trivial (ex: 10 servidores nginx)

2. **Camada de AplicaÃ§Ã£o (Estado TransitÃ³rio)**
   - Pode ter cache local ou sessÃµes de utilizador
   - ReplicaÃ§Ã£o: Complexa
   - SoluÃ§Ã£o: Armazenar sessÃµes em Redis (camada compartilhada)

3. **Camada de Dados (Estado Persistente)**
   - Dados crÃ­ticos, devem estar corretos
   - ReplicaÃ§Ã£o: Muito complexa

**Por que Ã© Mais FÃ¡cil Replicar ComputaÃ§Ã£o Stateless?**

**ComputaÃ§Ã£o Stateless (Web Server):**
```
Pedido 1: GET /api/products â†’ responde com lista de produtos
Pedido 2: GET /api/products â†’ responde com MESMA lista

Resultado: IdÃªntico, nÃ£o importa em qual servidor foi processado
```
- NÃ£o hÃ¡ memÃ³ria de pedidos anteriores
- Duas cÃ³pias processam idÃªntico â†’ SÃ­ncrono nÃ£o necessÃ¡rio
- Load balancer pode distribuir aleatoriamente

**Estado Persistente (Database):**
ReplicaÃ§Ã£o de estado Ã© exponencialmente mais complexa.

---

## 18. Cloud Services (IaaS / PaaS / SaaS)

### PrincÃ­pio Fundamental: Partilha de Responsabilidades

Ã€ medida que subimos na abstraÃ§Ã£o, delegamos mais responsabilidades ao fornecedor.

**IaaS**: Cliente gerencia aplicaÃ§Ãµes e SO. Fornecedor: infraestrutura.
**PaaS**: Cliente gerencia apenas aplicaÃ§Ãµes. Fornecedor: plataforma completa.
**SaaS**: Fornecedor gerencia tudo. Cliente apenas usa.

---

### ğŸ¯ PERGUNTAS SOBRE CLOUD SERVICES

**Pergunta 21: Partilha de Responsabilidades IaaS vs PaaS vs SaaS**

Explique o modelo de partilha de responsabilidades entre cliente e fornecedor em cada um dos trÃªs modelos de serviÃ§o cloud (IaaS, PaaS, SaaS). DÃª exemplos concretos.

**Resposta:**

**Responsabilidades em Cada Modelo:**

```
IaaS (Infrastructure as a Service)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† Cliente Gerido
â”‚ AplicaÃ§Ãµes         â”‚
â”‚ Dados              â”‚
â”‚ Middleware/Runtime â”‚
â”‚ Sistema Operativo  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â† Fornecedor Gerido
â”‚ VirtualizaÃ§Ã£o      â”‚
â”‚ Servidores         â”‚
â”‚ Armazenamento      â”‚
â”‚ Networking         â”‚
â”‚ Data Center        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PaaS (Platform as a Service)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† Cliente Gerido
â”‚ AplicaÃ§Ãµes         â”‚
â”‚ Dados              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â† Fornecedor Gerido
â”‚ Middleware/Runtime â”‚
â”‚ Sistema Operativo  â”‚
â”‚ VirtualizaÃ§Ã£o      â”‚
â”‚ Servidores         â”‚
â”‚ Armazenamento      â”‚
â”‚ Networking         â”‚
â”‚ Data Center        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SaaS (Software as a Service)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â† Fornecedor Gerido
â”‚ Tudo               â”‚
â”‚ (AplicaÃ§Ã£o,        â”‚
â”‚  Dados,            â”‚
â”‚  Infraestrutura)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â† Cliente apenas usa
```

**Exemplos Concretos:**

**IaaS: Amazon EC2**
- **Cliente gerido**: Escolher SO (Linux/Windows), instalar aplicaÃ§Ã£o, gerir backups
- **Fornecedor gerido**: Hardware, rede fÃ­sica, data center
- **Exemplo prÃ¡tico**: Aluga-se uma VM, instala-se Python + Django, faz-se deploy de aplicaÃ§Ã£o
- **Controlo**: MÃ¡ximo
- **Complexidade**: MÃ¡xima

**PaaS: Google App Engine**
- **Cliente gerido**: Escrever cÃ³digo Python/Java/Node.js
- **Fornecedor gerido**: Escalabilidade automÃ¡tica, BD gerida, deployment automÃ¡tico
- **Exemplo prÃ¡tico**: Upload de cÃ³digo, App Engine escala automaticamente conforme trÃ¡fego
- **Controlo**: MÃ©dio
- **Simplicidade**: MÃ©dia

**SaaS: Google Workspace (Gmail, Docs)**
- **Cliente gerido**: Apenas usar o serviÃ§o
- **Fornecedor gerido**: Tudo (servidores, seguranÃ§a, backups, updates)
- **Exemplo prÃ¡tico**: Aceder a Gmail.com, enviar emails
- **Controlo**: MÃ­nimo
- **Facilidade**: MÃ¡xima

---

**Pergunta 22: OpenStack como SoluÃ§Ã£o de IaaS Privada**

Descreva o OpenStack como exemplo de implementaÃ§Ã£o de uma nuvem IaaS privada. Qual Ã© a vantagem de uma nuvem privada relativamente a fornecedores pÃºblicos como AWS?

**Resposta:**

**O que Ã© OpenStack:**
OpenStack Ã© um software open-source que permite criar uma nuvem IaaS privada, controlando totalmente a infraestrutura de um data center sem depender de fornecedores externos.

**Vantagens da Nuvem Privada (OpenStack) vs PÃºblica (AWS):**

| Aspeto | Nuvem Privada (OpenStack) | Nuvem PÃºblica (AWS) |
|--------|--------------------------|-------------------|
| **Controlo** | Total (dentro da organizaÃ§Ã£o) | Nenhum (AWS controla) |
| **Dados SensÃ­veis** | Dentro de infraestrutura prÃ³pria | Em servidores AWS (overseas?) |
| **Conformidade** | Mais fÃ¡cil cumprir regulaÃ§Ãµes (GDPR, HIPAA) | Complexo (dados fora de controlo) |
| **Custo Inicial** | Alto (investimento em hardware) | Baixo (pay-per-use) |
| **Custo Operacional** | Alto (necessÃ¡rio DevOps) | Baixo (AWS gerencia) |
| **Escalabilidade** | Limitada ao hardware disponÃ­vel | Praticamente ilimitada |
| **LatÃªncia** | Potencialmente menor (infraestrutura local) | Depende da localizaÃ§Ã£o |
| **Vendor Lock-in** | Nenhum (open-source) | Forte (AWS proprietÃ¡rio) |

**Quando Usar OpenStack:**
- OrganizaÃ§Ãµes com dados muito sensÃ­veis (financeiros, saÃºde)
- Conformidade regulatÃ³ria rigorosa
- Grandes volumes de dados (evitar custos de transferÃªncia)
- Necessidade de controlo total
- JÃ¡ possuem data center

**Quando Usar AWS:**
- Startups com orÃ§amento limitado
- Escalabilidade dinÃ¢mica imprescindÃ­vel
- NÃ£o hÃ¡ expertise DevOps interno
- AplicaÃ§Ãµes globais (multi-regiÃ£o)

---

## 27. Benchmarking

### Os TrÃªs Pilares de um Benchmark

1. **Workload**: Conjunto de pedidos (traces reais vs. sintÃ©ticas)
2. **Environment**: Hardware e software documentado
3. **Metrics**: O que medimos

### 27.2 As MÃ©tricas: O que Medimos?

**LatÃªncia**: Tempo entre pedido e resposta
**Throughput**: NÃºmero de pedidos processados por segundo

---

### ğŸ¯ PERGUNTAS SOBRE BENCHMARKING

**Pergunta 25: LatÃªncia vs Throughput - O Compromisso Fundamental**

Explique a relaÃ§Ã£o entre latÃªncia e throughput sob carga crescente. Por que Ã© que aumentar throughput nÃ£o diminui necessariamente latÃªncia, e vice-versa? DÃª um exemplo de otimizaÃ§Ã£o que melhora throughput mas piora latÃªncia.

**Resposta:**

**DefiniÃ§Ãµes BÃ¡sicas:**
- **LatÃªncia (L)**: Tempo entre pedido e resposta (ex: 50ms)
- **Throughput (T)**: NÃºmero de pedidos processados por segundo (ex: 1000 req/s)

**RelaÃ§Ã£o Intuitiva Errada:**
Muitos pensam: L = 1 / T (relaÃ§Ã£o inversa simples)
- Se T = 1000 req/s, entÃ£o L = 1ms?
- Isto Ã© **FALSO**

**RelaÃ§Ã£o Real (Verdadeira) sob Carga Crescente:**

Existem 3 fases:

```
Fase 1: Idle/Vazio (Carga Baixa)
System tem capacidade de sobra
Throughput: Cresce linearmente
LatÃªncia: Permanece baixa

Fase 2: Near Capacity (Carga MÃ©dia)
Filas comeÃ§am a formar (Little's Law)
Throughput: Aproxima-se do mÃ¡ximo
LatÃªncia: ComeÃ§a a subir

Fase 3: Overload (Carga Alta)
Sistema saturado, muitas filas, contenÃ§Ã£o CPU
Throughput: Estagna ou cai
LatÃªncia: Dispara exponencialmente
```

**Little's Law:**
```
LatÃªncia = (Tamanho Fila + Tempo ServiÃ§o) / Throughput

Ã€ medida que carga sobe, fila cresce exponencialmente em overload.
Portanto, LatÃªncia cresce exponencialmente.
```

**Exemplo PrÃ¡tico: Batching**

OtimizaÃ§Ã£o: Agrupar 100 pedidos e processar como 1 batch

**Sem Batching:**
- 100 pedidos individuais: 100 Ã— 10ms = 1000ms total
- Throughput: 100 req/s
- LatÃªncia individual: 10ms

**Com Batching:**
- 1 batch de 100: Processamento paralelo = 50ms
- Throughput: 2000 req/s (20x melhor!)
- LatÃªncia individual: 50ms (5x pior!)

```
      Throughput (req/s)  â”‚  LatÃªncia (ms)
                          â”‚
   Sem Batch: 100         â”‚  Sem Batch: 10
   Com Batch: 2000        â”‚  Com Batch: 50
   
   âœ“ 20x melhor throughputâ”‚  âœ— 5x pior latÃªncia
   âœ— Pior para clients    â”‚  âœ“ Melhor para sistema
   individuais            â”‚
```

**ConclusÃ£o:**
LatÃªncia e Throughput **nÃ£o sÃ£o inversamente proporcionais**. Sob carga:
- Fase 1: Ambas melhoram
- Fase 2: Compromisso (throughput sobe, latÃªncia sobe lentamente)
- Fase 3: Tradeoff direto (aumentar throughput piora latÃªncia)

A melhor estratÃ©gia Ã© **permanecer na Fase 1-2** (antes de saturaÃ§Ã£o) atravÃ©s de:
- Auto-scaling (adicionar servidores)
- OtimizaÃ§Ã£o (cache, batching consoante requisito)
- MonitorizaÃ§Ã£o (detetar antes de atingir Fase 3)

---

## RESUMO DAS 25 PERGUNTAS POR TÃ“PICO

| TÃ³pico | Perguntas |
|--------|-----------|
| **VirtualizaÃ§Ã£o** | 1, 2, 3 |
| **Contentores/Docker** | 4, 5, 6 |
| **Kubernetes** | 7, 8, 9 |
| **Armazenamento** | 10, 11, 12 |
| **Ansible/Provisioning** | 13, 14, 15 |
| **MonitorizaÃ§Ã£o** | 16, 17, 18 |
| **Arquiteturas DistribuÃ­das** | 19, 20 |
| **Cloud Services** | 21, 22 |
| **DevOps** | 23, 24 |
| **Benchmarking** | 25 |

---

**Fim do Documento**
**Total: 25 Perguntas + Respostas Integradas nas SecÃ§Ãµes Correspondentes**